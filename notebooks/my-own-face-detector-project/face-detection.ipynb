{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12d281c-be07-41b3-b06f-0beeb3ca9772",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc654561-70d0-47c1-8c75-d3c6ee01bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac0a32d0-a561-4811-8c1b-a6b51e05ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.path.join(os.getcwd(), 'my-own-face-detector-project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae0f5da-5ba6-47b3-a36f-4fddcd2e0493",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join(PROJECT_PATH, 'datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ebecf9-a223-40da-9660-89b91a31ad19",
   "metadata": {},
   "source": [
    "## Augmenting the Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41924f79-4c1d-4a23-b78c-351b88bed443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 265 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/devrrior/Repos/my_lab_ai/notebooks/my-own-face-detector-project/datasets',\n",
    "    target_size=(224,224),\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd37aeb-d081-40b5-a53a-b5eea4c52b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices.values()\n",
    "# dict_values([0, 1, 2])\n",
    "NO_CLASSES = len(train_generator.class_indices.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab202d0-4570-430f-ae60-20c5cd8ce90b",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02960d7f-7757-4b44-8945-59839c6ead1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vggface_vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "base_model = VGGFace(include_top=False,\n",
    "model='vgg16',\n",
    "input_shape=(224, 224, 3))\n",
    "base_model.summary()\n",
    "print(len(base_model.layers))\n",
    "# 19 layers after excluding the last few layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a1fafe-0884-4874-ae48-b1a06ba44d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "# final layer with softmax activation\n",
    "preds = Dense(NO_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e34dfb-28f0-42b5-a8e6-7b0b69b418c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,815,426\n",
      "Trainable params: 16,815,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create a new model with the base model's original input and the \n",
    "# new model's output\n",
    "model = Model(inputs = base_model.input, outputs = preds)\n",
    "model.summary()\n",
    "\n",
    "# don't train the first 19 layers - 0..18\n",
    "for layer in model.layers[:19]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# train the rest of the layers - 19 onwards\n",
    "for layer in model.layers[19:]:\n",
    "    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f3105cf-9aca-488b-af55-2b7d98080e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "705e07ec-925f-493f-a41a-da9a3bdcc2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "9/9 [==============================] - 36s 4s/step - loss: 4.4985e-10 - accuracy: 1.0000\n",
      "Epoch 2/8\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/8\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/8\n",
      "9/9 [==============================] - 41s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/8\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/8\n",
      "9/9 [==============================] - 45s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/8\n",
      "9/9 [==============================] - 47s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/8\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2878cc4f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,\n",
    "  batch_size = 1,\n",
    "  verbose = 1,\n",
    "  epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb727a4-e065-4d41-ac4a-263ad16e93c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a HDF5 file\n",
    "model.save(\n",
    "    './face_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d2289-00be-42f0-aeb7-f83f070bc67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# deletes the existing model\n",
    "del model\n",
    "\n",
    "# returns a compiled model identical to the previous one\n",
    "model = load_model(\n",
    "\n",
    "    './face_cnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd496533-281a-46ff-b745-6b93d5f9bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class_dictionary = train_generator.class_indices\n",
    "class_dictionary = {\n",
    "    value:key for key, value in class_dictionary.items()\n",
    "}\n",
    "print(class_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cfcfa6-d7da-45c4-a85d-56aeeba87dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the class dictionary to pickle\n",
    "face_label_filename = 'face-labels.pickle'\n",
    "with open(face_label_filename, 'wb') as f: pickle.dump(class_dictionary, f)\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras_vggface import utils\n",
    "\n",
    "# dimension of images\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "# load the training labels\n",
    "face_label_filename = 'face-labels.pickle'\n",
    "with open(face_label_filename, \"rb\") as \\\n",
    "    f: class_dictionary = pickle.load(f)\n",
    "\n",
    "class_list = [value for _, value in class_dictionary.items()]\n",
    "print(class_list)\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras_vggface import utils\n",
    "\n",
    "# dimension of images\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "# load the training labels\n",
    "face_label_filename = 'face-labels.pickle'\n",
    "with open(face_label_filename, \"rb\") as \\\n",
    "    f: class_dictionary = pickle.load(f)\n",
    "\n",
    "class_list = [value for _, value in class_dictionary.items()]\n",
    "print(class_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd7ff5b-0076-4c75-bdac-ba2043b139f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras_vggface import utils\n",
    "\n",
    "# dimension of images\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "# load the training labels\n",
    "face_label_filename = 'face-labels.pickle'\n",
    "with open(face_label_filename, \"rb\") as f:\n",
    "    class_dictionary = pickle.load(f)\n",
    "\n",
    "class_list = [value for _, value in class_dictionary.items()]\n",
    "print(class_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc22c6-f3ec-45a0-abd7-bb1fed7f5182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mtcnn\n",
    "face_detector = mtcnn.MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec46c6-9d99-4027-b2ba-80d24ecd83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, width, height):\n",
    "    image_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "\n",
    "    processed_images = []\n",
    "\n",
    "    for image_file in image_files:\n",
    "        if image_file.endswith('.jpg') or image_file.endswith('.jpeg'):\n",
    "            image_path = os.path.join(path, image_file)\n",
    "            print(image_path)\n",
    "            image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "            img_roi = face_detector.detect_faces(image)\n",
    "    \n",
    "            if img_roi:\n",
    "                x1, y1, width, height = img_roi[0][\"box\"]\n",
    "                x2, y2 = x1 + width, y1 + height\n",
    "                face = image[y1:y2, x1:x2]\n",
    "                face = cv2.resize(face, (224,224))\n",
    "    \n",
    "                processed_images.append(face)\n",
    "                print(face.shape)\n",
    "                plt.imshow(face)\n",
    "                plt.show()\n",
    "\n",
    "    processed_images_array = np.array(processed_images)\n",
    "\n",
    "    return processed_images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664ef77-62a8-491e-9a54-ea8a8bc7447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples1 = load_images('/Users/devrrior/Repos/my_lab_ai/notebooks/my-own-face-detector-project/test', 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a93400-148e-4d96-a24d-4fbffb8effc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prob = model.predict(samples1)\n",
    "print(predicted_prob)\n",
    "print(predicted_prob[0].argmax())\n",
    "print(\"Predicted face: \" + class_list[predicted_prob[3].argmax()])\n",
    "print(\"============================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db49ebe0-9356-4358-9416-1dc4ea01b38e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
